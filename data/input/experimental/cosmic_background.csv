import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.fft import fft, fftfreq
import seaborn as sns

class CosmicDataAnalyzer:
    """
    Analizador de datos c√≥smicos para el simulador MFSU
    Incluye an√°lisis fractal, espectral y validaci√≥n de par√°metros cosmol√≥gicos
    """
    
    def __init__(self, csv_file='cosmic_background.csv'):
        """Inicializar con archivo CSV"""
        self.data = pd.read_csv(csv_file)
        self.setup_analysis()
    
    def setup_analysis(self):
        """Configurar an√°lisis inicial"""
        print("=== AN√ÅLISIS DE DATOS C√ìSMICOS MFSU ===")
        print(f"Datos cargados: {len(self.data)} puntos")
        print(f"Tipos de datos: {list(self.data['type'].unique())}")
        
        # Separar datos por tipo
        self.angular_data = self.data[self.data['type'] == 'angular_spectrum'].copy()
        self.redshift_data = self.data[self.data['type'] == 'redshift_evolution'].copy()
        self.spatial_data = self.data[self.data['type'] == 'spatial_3d'].copy()
        self.benchmark_data = self.data[self.data['type'] == 'mfsu_benchmark'].copy()
        
    def analyze_fractal_properties(self):
        """An√°lisis de propiedades fractales"""
        print("\n=== AN√ÅLISIS FRACTAL ===")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Distribuci√≥n de exponentes de Hurst
        axes[0,0].hist(self.data['hurst_exponent'].dropna(), bins=30, alpha=0.7, color='blue')
        axes[0,0].axvline(0.7, color='red', linestyle='--', label='H=0.7 (referencia)')
        axes[0,0].set_xlabel('Exponente de Hurst')
        axes[0,0].set_ylabel('Frecuencia')
        axes[0,0].set_title('Distribuci√≥n de Exponentes de Hurst')
        axes[0,0].legend()
        
        # 2. Distribuci√≥n de dimensiones fractales
        axes[0,1].hist(self.data['fractal_dimension'].dropna(), bins=30, alpha=0.7, color='green')
        axes[0,1].axvline(2.3, color='red', linestyle='--', label='D=2.3 (referencia)')
        axes[0,1].set_xlabel('Dimensi√≥n Fractal')
        axes[0,1].set_ylabel('Frecuencia')
        axes[0,1].set_title('Distribuci√≥n de Dimensiones Fractales')
        axes[0,1].legend()
        
        # 3. Correlaci√≥n H vs D
        valid_mask = self.data['hurst_exponent'].notna() & self.data['fractal_dimension'].notna()
        h_vals = self.data.loc[valid_mask, 'hurst_exponent']
        d_vals = self.data.loc[valid_mask, 'fractal_dimension']
        
        axes[1,0].scatter(h_vals, d_vals, alpha=0.6, c=self.data.loc[valid_mask, 'stochastic_amplitude'], 
                         cmap='viridis')
        axes[1,0].set_xlabel('Exponente de Hurst')
        axes[1,0].set_ylabel('Dimensi√≥n Fractal')
        axes[1,0].set_title('Correlaci√≥n H vs D (color = amplitud estoc√°stica)')
        
        # Relaci√≥n te√≥rica D = 3 - H para fBm en 2D
        h_theory = np.linspace(0.1, 0.9, 100)
        d_theory = 3 - h_theory
        axes[1,0].plot(h_theory, d_theory, 'r--', label='D = 3 - H (te√≥rico)')
        axes[1,0].legend()
        
        # 4. Amplitud estoc√°stica por tipo
        for i, data_type in enumerate(['angular_spectrum', 'redshift_evolution', 'spatial_3d']):
            subset = self.data[self.data['type'] == data_type]
            if not subset.empty:
                axes[1,1].hist(subset['stochastic_amplitude'].dropna(), bins=20, 
                             alpha=0.5, label=data_type)
        
        axes[1,1].set_xlabel('Amplitud Estoc√°stica')
        axes[1,1].set_ylabel('Frecuencia')
        axes[1,1].set_title('Distribuci√≥n de Amplitudes Estoc√°sticas')
        axes[1,1].legend()
        
        plt.tight_layout()
        plt.savefig('fractal_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas fractales
        print(f"Hurst promedio: {self.data['hurst_exponent'].mean():.3f} ¬± {self.data['hurst_exponent'].std():.3f}")
        print(f"Dimensi√≥n fractal promedio: {self.data['fractal_dimension'].mean():.3f} ¬± {self.data['fractal_dimension'].std():.3f}")
        
    def analyze_cmb_spectrum(self):
        """An√°lisis del espectro de potencias del CMB"""
        print("\n=== AN√ÅLISIS ESPECTRO CMB ===")
        
        if self.angular_data.empty:
            print("No hay datos espectrales disponibles")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Espectro de potencias C_l vs l
        l_vals = self.angular_data['l_multipole'].values
        c_l_vals = self.angular_data['power_spectrum_C_l'].values
        
        axes[0,0].loglog(l_vals, c_l_vals * l_vals * (l_vals + 1), 'b-', alpha=0.7)
        axes[0,0].set_xlabel('Multipolo l')
        axes[0,0].set_ylabel('l(l+1)C_l / 2œÄ')
        axes[0,0].set_title('Espectro de Potencias Angular del CMB')
        axes[0,0].grid(True, alpha=0.3)
        
        # 2. Fluctuaciones de temperatura
        delta_T = self.angular_data['delta_T_microK'].values
        axes[0,1].semilogx(l_vals, delta_T, 'r-', alpha=0.7)
        axes[0,1].set_xlabel('Multipolo l')
        axes[0,1].set_ylabel('ŒîT (ŒºK)')
        axes[0,1].set_title('Fluctuaciones de Temperatura vs Escala Angular')
        axes[0,1].grid(True, alpha=0.3)
        
        # 3. An√°lisis de periodicidades (picos ac√∫sticos)
        # FFT del espectro para detectar oscilaciones
        spectrum_smooth = np.log(c_l_vals)
        fft_spectrum = np.abs(fft(spectrum_smooth))
        freqs = fftfreq(len(spectrum_smooth))
        
        axes[1,0].plot(freqs[:len(freqs)//2], fft_spectrum[:len(freqs)//2])
        axes[1,0].set_xlabel('Frecuencia en log(l)')
        axes[1,0].set_ylabel('Amplitud FFT')
        axes[1,0].set_title('An√°lisis de Periodicidades (Picos Ac√∫sticos)')
        axes[1,0].grid(True, alpha=0.3)
        
        # 4. Distribuci√≥n estad√≠stica de fluctuaciones
        axes[1,1].hist(delta_T, bins=30, alpha=0.7, density=True, color='purple')
        
        # Ajustar distribuci√≥n gaussiana
        mu, sigma = stats.norm.fit(delta_T)
        x_gauss = np.linspace(delta_T.min(), delta_T.max(), 100)
        y_gauss = stats.norm.pdf(x_gauss, mu, sigma)
        axes[1,1].plot(x_gauss, y_gauss, 'r-', label=f'Gaussiana Œº={mu:.1f}, œÉ={sigma:.1f}')
        
        axes[1,1].set_xlabel('ŒîT (ŒºK)')
        axes[1,1].set_ylabel('Densidad de Probabilidad')
        axes[1,1].set_title('Distribuci√≥n de Fluctuaciones de Temperatura')
        axes[1,1].legend()
        
        plt.tight_layout()
        plt.savefig('cmb_spectrum_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas del CMB
        print(f"Rango de multipolos: {l_vals.min():.1f} - {l_vals.max():.1f}")
        print(f"ŒîT promedio: {delta_T.mean():.2f} ¬± {delta_T.std():.2f} ŒºK")
        print(f"Amplitud C_l m√°xima en l={l_vals[np.argmax(c_l_vals)]:.1f}")
        
    def analyze_cosmological_evolution(self):
        """An√°lisis de evoluci√≥n cosmol√≥gica"""
        print("\n=== AN√ÅLISIS EVOLUCI√ìN COSMOL√ìGICA ===")
        
        if self.redshift_data.empty:
            print("No hay datos de evoluci√≥n disponibles")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        z_vals = self.redshift_data['redshift'].values
        T_vals = self.redshift_data['temperature_K'].values
        H_vals = self.redshift_data['H0_km_s_Mpc'].values
        
        # 1. Evoluci√≥n de temperatura T(z)
        axes[0,0].loglog(1 + z_vals, T_vals, 'bo-', alpha=0.7, markersize=3)
        
        # Ley te√≥rica T ‚àù (1+z)
        T_theory = 2.7255 * (1 + z_vals)
        axes[0,0].loglog(1 + z_vals, T_theory, 'r--', label='T ‚àù (1+z)')
        
        axes[0,0].set_xlabel('1 + z')
        axes[0,0].set_ylabel('Temperatura (K)')
        axes[0,0].set_title('Evoluci√≥n de la Temperatura del CMB')
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3)
        
        # 2. Par√°metro de Hubble H(z)
        axes[0,1].semilogx(z_vals, H_vals, 'go-', alpha=0.7, markersize=3)
        axes[0,1].set_xlabel('Redshift z')
        axes[0,1].set_ylabel('H(z) (km/s/Mpc)')
        axes[0,1].set_title('Evoluci√≥n del Par√°metro de Hubble')
        axes[0,1].grid(True, alpha=0.3)
        
        # 3. Evoluci√≥n de propiedades fractales
        h_evolution = self.redshift_data['hurst_exponent'].values
        axes[1,0].semilogx(z_vals, h_evolution, 'mo', alpha=0.7, markersize=3)
        axes[1,0].set_xlabel('Redshift z')
        axes[1,0].set_ylabel('Exponente de Hurst')
        axes[1,0].set_title('Evoluci√≥n de Propiedades Fractales')
        axes[1,0].grid(True, alpha=0.3)
        
        # 4. Acoplamiento no lineal vs redshift
        nonlinear = self.redshift_data['nonlinear_coupling'].values
        axes[1,1].loglog(1 + z_vals, nonlinear, 'co-', alpha=0.7, markersize=3)
        axes[1,1].set_xlabel('1 + z')
        axes[1,1].set_ylabel('Acoplamiento No Lineal')
        axes[1,1].set_title('Evoluci√≥n del Acoplamiento No Lineal MFSU')
        axes[1,1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('cosmological_evolution.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Validaci√≥n cosmol√≥gica
        z_recomb = 1100  # Redshift de recombinaci√≥n
        idx_recomb = np.argmin(np.abs(z_vals - z_recomb))
        T_recomb = T_vals[idx_recomb]
        T_recomb_theory = 2.7255 * (1 + z_recomb)
        
        print(f"Temperatura en recombinaci√≥n (z‚âà1100):")
        print(f"  Simulada: {T_recomb:.1f} K")
        print(f"  Te√≥rica: {T_recomb_theory:.1f} K")
        print(f"  Error relativo: {abs(T_recomb - T_recomb_theory)/T_recomb_theory * 100:.2f}%")
        
    def analyze_spatial_distribution(self):
        """An√°lisis de distribuci√≥n espacial 3D"""
        print("\n=== AN√ÅLISIS DISTRIBUCI√ìN ESPACIAL ===")
        
        if self.spatial_data.empty:
            print("No hay datos espaciales disponibles")
            return
        
        fig = plt.figure(figsize=(15, 12))
        
        x = self.spatial_data['x_position_Mpc'].values
        y = self.spatial_data['y_position_Mpc'].values
        z = self.spatial_data['z_position_Mpc'].values
        temp = self.spatial_data['temperature_K'].values
        
        # 1. Distribuci√≥n 3D con colores por temperatura
        ax1 = fig.add_subplot(221, projection='3d')
        scatter = ax1.scatter(x, y, z, c=temp, cmap='plasma', alpha=0.6, s=20)
        ax1.set_xlabel('X (Mpc)')
        ax1.set_ylabel('Y (Mpc)')
        ax1.set_zlabel('Z (Mpc)')
        ax1.set_title('Distribuci√≥n Espacial 3D')
        plt.colorbar(scatter, ax=ax1, label='Temperatura (K)', shrink=0.6)
        
        # 2. Proyecci√≥n XY
        ax2 = fig.add_subplot(222)
        scatter2 = ax2.scatter(x, y, c=temp, cmap='plasma', alpha=0.7, s=15)
        ax2.set_xlabel('X (Mpc)')
        ax2.set_ylabel('Y (Mpc)')
        ax2.set_title('Proyecci√≥n XY')
        ax2.grid(True, alpha=0.3)
        plt.colorbar(scatter2, ax=ax2, label='Temperatura (K)')
        
        # 3. Funci√≥n de correlaci√≥n radial
        distances = np.sqrt(x**2 + y**2 + z**2)
        
        ax3 = fig.add_subplot(223)
        ax3.scatter(distances, temp - temp.mean(), alpha=0.6, s=10)
        ax3.set_xlabel('Distancia al origen (Mpc)')
        ax3.set_ylabel('ŒîT - <T> (K)')
        ax3.set_title('Correlaci√≥n Radial de Temperatura')
        ax3.grid(True, alpha=0.3)
        
        # 4. An√°lisis de clustering
        ax4 = fig.add_subplot(224)
        
        # Histograma de distancias
        ax4.hist(distances, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax4.set_xlabel('Distancia radial (Mpc)')
        ax4.set_ylabel('N√∫mero de puntos')
        ax4.set_title('Distribuci√≥n Radial de Datos')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('spatial_distribution.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas espaciales
        print(f"Rango espacial: {distances.min():.2f} - {distances.max():.2f} Mpc")
        print(f"Temperatura promedio: {temp.mean():.6f} ¬± {temp.std():.6f} K")
        
        # An√°lisis de homogeneidad (test de Kolmogorov-Smirnov)
        # Comparar distribuci√≥n de temperaturas con distribuci√≥n uniforme
        uniform_temps = np.random.uniform(temp.min(), temp.max(), len(temp))
        ks_stat, ks_p = stats.ks_2samp(temp, uniform_temps)
        print(f"Test KS para homogeneidad: estad√≠stico={ks_stat:.4f}, p-value={ks_p:.4f}")
        
    def analyze_mfsu_benchmarks(self):
        """An√°lisis de datos de benchmarking MFSU"""
        print("\n=== AN√ÅLISIS BENCHMARKS MFSU ===")
        
        if self.benchmark_data.empty:
            print("No hay datos de benchmark disponibles")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        t_vals = self.benchmark_data['x_position_Mpc'].values  # Tiempo
        psi_real = self.benchmark_data['y_position_Mpc'].values
        psi_imag = self.benchmark_data['z_position_Mpc'].values
        psi_mag = np.sqrt(psi_real**2 + psi_imag**2)
        power = self.benchmark_data['power_spectrum_C_l'].values
        
        # 1. Evoluci√≥n temporal de la funci√≥n de onda
        axes[0,0].plot(t_vals, psi_real, 'b-', label='Re(œà)', linewidth=2)
        axes[0,0].plot(t_vals, psi_imag, 'r-', label='Im(œà)', linewidth=2)
        axes[0,0].plot(t_vals, psi_mag, 'k--', label='|œà|', linewidth=2)
        axes[0,0].set_xlabel('Tiempo (adimensional)')
        axes[0,0].set_ylabel('Amplitud œà')
        axes[0,0].set_title('Evoluci√≥n Temporal MFSU')
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3)
        
        # 2. Espectro de potencias |œà|¬≤
        axes[0,1].semilogy(t_vals, power, 'g-', linewidth=2)
        axes[0,1].set_xlabel('Tiempo (adimensional)')
        axes[0,1].set_ylabel('|œà|¬≤')
        axes[0,1].set_title('Espectro de Potencias MFSU')
        axes[0,1].grid(True, alpha=0.3)
        
        # 3. Diagrama de fases (Re vs Im)
        axes[1,0].plot(psi_real, psi_imag, 'purple', alpha=0.7, linewidth=1)
        axes[1,0].scatter(psi_real[0], psi_imag[0], color='green', s=100, marker='o', label='Inicio')
        axes[1,0].scatter(psi_real[-1], psi_imag[-1], color='red', s=100, marker='s', label='Final')
        axes[1,0].set_xlabel('Re(œà)')
        axes[1,0].set_ylabel('Im(œà)')
        axes[1,0].set_title('Diagrama de Fases MFSU')
        axes[1,0].legend()
        axes[1,0].grid(True, alpha=0.3)
        axes[1,0].axis('equal')
        
        # 4. An√°lisis de decaimiento exponencial
        # Ajustar decaimiento exponencial a |œà|
        def exponential_decay(t, A, gamma):
            return A * np.exp(-gamma * t)
        
        from scipy.optimize import curve_fit
        
        try:
            popt, pcov = curve_fit(exponential_decay, t_vals, psi_mag, p0=[1.0, 0.5])
            A_fit, gamma_fit = popt
            
            axes[1,1].semilogy(t_vals, psi_mag, 'bo', alpha=0.7, markersize=4, label='Datos')
            axes[1,1].semilogy(t_vals, exponential_decay(t_vals, A_fit, gamma_fit), 
                              'r-', linewidth=2, label=f'Ajuste: A={A_fit:.3f}, Œ≥={gamma_fit:.3f}')
            axes[1,1].set_xlabel('Tiempo (adimensional)')
            axes[1,1].set_ylabel('|œà|')
            axes[1,1].set_title('An√°lisis de Decaimiento Exponencial')
            axes[1,1].legend()
            axes[1,1].grid(True, alpha=0.3)
            
            print(f"Par√°metros de ajuste exponencial:")
            print(f"  Amplitud inicial: {A_fit:.4f}")
            print(f"  Tasa de decaimiento: {gamma_fit:.4f}")
            
        except Exception as e:
            axes[1,1].text(0.5, 0.5, f'Error en ajuste:\n{str(e)}', 
                          transform=axes[1,1].transAxes, ha='center', va='center')
        
        plt.tight_layout()
        plt.savefig('mfsu_benchmarks.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Conservaci√≥n de norma
        norm_conservation = np.trapz(power, t_vals)
        print(f"Conservaci√≥n de norma ‚à´|œà|¬≤dt = {norm_conservation:.4f}")
        
    def generate_validation_report(self):
        """Generar reporte de validaci√≥n completo"""
        print("\n" + "="*60)
        print("REPORTE DE VALIDACI√ìN COSMIC_BACKGROUND.CSV")
        print("="*60)
        
        # Validaciones b√°sicas
        missing_data = self.data.isnull().sum()
        print("\n1. INTEGRIDAD DE DATOS:")
        print(f"   Total de registros: {len(self.data)}")
        print(f"   Columnas con datos faltantes:")
        for col, count in missing_data.items():
            if count > 0:
                print(f"     {col}: {count} ({count/len(self.data)*100:.1f}%)")
        
        # Validaciones f√≠sicas
        print("\n2. VALIDACIONES F√çSICAS:")
        
        # Temperatura del CMB
        T_cmb_data = self.data['temperature_K'].dropna()
        if len(T_cmb_data) > 0:
            T_min, T_max = T_cmb_data.min(), T_cmb_data.max()
            print(f"   Rango de temperaturas: {T_min:.3f} - {T_max:.3f} K")
            if T_min < 0:
                print("   ‚ö†Ô∏è  ADVERTENCIA: Temperaturas negativas detectadas")
            if T_max > 3000:
                print("   ‚ö†Ô∏è  ADVERTENCIA: Temperaturas excesivamente altas")
        
        # Par√°metros cosmol√≥gicos
        H0_vals = self.data['H0_km_s_Mpc'].dropna()
        if len(H0_vals) > 0:
            H0_range = [H0_vals.min(), H0_vals.max()]
            print(f"   Rango H‚ÇÄ: {H0_range[0]:.1f} - {H0_range[1]:.1f} km/s/Mpc")
            if H0_range[0] < 50 or H0_range[1] > 100:
                print("   ‚ö†Ô∏è  ADVERTENCIA: Valores de H‚ÇÄ fuera del rango observacional")
        
        Omega_m = self.data['Omega_m'].dropna().iloc[0] if not self.data['Omega_m'].dropna().empty else None
        Omega_lambda = self.data['Omega_lambda'].dropna().iloc[0] if not self.data['Omega_lambda'].dropna().empty else None
        if Omega_m is not None and Omega_lambda is not None:
            Omega_total = Omega_m + Omega_lambda
            print(f"   Œ©‚Çò + Œ©‚Çó = {Omega_total:.3f}")
            if abs(Omega_total - 1.0) > 0.1:
                print("   ‚ö†Ô∏è  ADVERTENCIA: Universo no plano (Œ©‚Çú‚Çí‚Çú‚Çê‚Çó ‚â† 1)")
        
        # Propiedades fractales
        print("\n3. PROPIEDADES FRACTALES:")
        H_vals = self.data['hurst_exponent'].dropna()
        if len(H_vals) > 0:
            print(f"   Exponente de Hurst: {H_vals.mean():.3f} ¬± {H_vals.std():.3f}")
            if (H_vals < 0).any() or (H_vals > 1).any():
                print("   ‚ö†Ô∏è  ADVERTENCIA: Exponentes de Hurst fuera de [0,1]")
        
        D_vals = self.data['fractal_dimension'].dropna()
        if len(D_vals) > 0:
            print(f"   Dimensi√≥n fractal: {D_vals.mean():.3f} ¬± {D_vals.std():.3f}")
            if (D_vals < 1).any() or (D_vals > 3).any():
                print("   ‚ö†Ô∏è  ADVERTENCIA: Dimensiones fractales fuera de [1,3]")
        
        # Compatibilidad con MFSU
        print("\n4. COMPATIBILIDAD MFSU:")
        stoch_amp = self.data['stochastic_amplitude'].dropna()
        if len(stoch_amp) > 0:
            print(f"   Amplitud estoc√°stica: {stoch_amp.mean():.4f} ¬± {stoch_amp.std():.4f}")
        
        nonlin_coup = self.data['nonlinear_coupling'].dropna()
        if len(nonlin_coup) > 0:
            print(f"   Acoplamiento no lineal: {nonlin_coup.mean():.4f} ¬± {nonlin_coup.std():.4f}")
        
        print("\n5. RECOMENDACIONES:")
        print("   ‚úì Los datos est√°n estructurados para aplicaciones MFSU")
        print("   ‚úì Incluye m√∫ltiples escalas (angular, temporal, espacial)")
        print("   ‚úì Propiedades fractales dentro de rangos f√≠sicos")
        print("   ‚úì Datos de benchmark para validaci√≥n num√©rica")
        
        if len(missing_data[missing_data > 0]) > 0:
            print("   üìù Considere completar datos faltantes seg√∫n la aplicaci√≥n espec√≠fica")
        
        print("\n" + "="*60)
        
    def run_complete_analysis(self):
        """Ejecutar an√°lisis completo"""
        print("Iniciando an√°lisis completo de cosmic_background.csv...")
        
        try:
            self.analyze_fractal_properties()
            self.analyze_cmb_spectrum()
            self.analyze_cosmological_evolution()
            self.analyze_spatial_distribution()
            self.analyze_mfsu_benchmarks()
            self.generate_validation_report()
            
            print("\nüéâ An√°lisis completo finalizado exitosamente!")
            print("üìä Gr√°ficos guardados: fractal_analysis.png, cmb_spectrum_analysis.png,")
            print("    cosmological_evolution.png, spatial_distribution.png, mfsu_benchmarks.png")
            
        except Exception as e:
            print(f"\n‚ùå Error durante el an√°lisis: {str(e)}")
            import traceback
            traceback.print_exc()

def main():
    """Funci√≥n principal para ejecutar el an√°lisis"""
    import sys
    
    # Determinar archivo de entrada
    csv_file = sys.argv[1] if len(sys.argv) > 1 else 'cosmic_background.csv'
    
    try:
        # Crear analizador
        analyzer = CosmicDataAnalyzer(csv_file)
        
        # Ejecutar an√°lisis completo
        analyzer.run_complete_analysis()
        
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ el archivo {csv_file}")
        print("üí° Ejecute primero el generador de datos c√≥smicos")
        
    except Exception as e:
        print(f"‚ùå Error inesperado: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
